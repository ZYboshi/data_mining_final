import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import os
import sys

# åˆ›å»ºå¿…è¦çš„ç›®å½•
def create_directories():
    """åˆ›å»ºä¿å­˜ç»“æœæ‰€éœ€çš„ç›®å½•ç»“æ„"""
    base_dir = './preprocess_dataset'
    outliers_dir = f'{base_dir}/outliers'
    
    # åˆ›å»ºç›®å½•
    os.makedirs(base_dir, exist_ok=True)
    os.makedirs(outliers_dir, exist_ok=True)
    
    print(f"âœ… å·²åˆ›å»ºç›®å½•ç»“æ„:")
    print(f"   - {base_dir}")
    print(f"   - {outliers_dir}")
    
    return outliers_dir

def load_data_and_info(dataset_dir='./dataset'):
    """åŠ è½½æ•°æ®å’Œåˆ—ä¿¡æ¯"""
    try:
        # æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
        data_path = os.path.join(dataset_dir, 'bank_marketing_aftermissing.csv')
        info_path = os.path.join(dataset_dir, 'column_info_aftermissing.json')
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(data_path):
            raise FileNotFoundError(f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        if not os.path.exists(info_path):
            raise FileNotFoundError(f"åˆ—ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨: {info_path}")
        
        # åŠ è½½æ•°æ®
        print(f"ğŸ“ æ­£åœ¨åŠ è½½æ•°æ®é›†: {data_path}")
        data = pd.read_csv(data_path)
        
        # åŠ è½½åˆ—ä¿¡æ¯
        print(f"ğŸ“ æ­£åœ¨åŠ è½½åˆ—ä¿¡æ¯: {info_path}")
        with open(info_path, 'r') as f:
            column_info = json.load(f)
        
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ!")
        print(f"   æ•°æ®å½¢çŠ¶: {data.shape}")
        print(f"   åˆ—ä¿¡æ¯: {len(column_info['columns'])} ä¸ªç‰¹å¾")
        
        # æ£€æŸ¥åˆ—åä¸€è‡´æ€§
        data_columns = set(data.columns)
        info_columns = set(column_info['columns'].keys())
        
        if not data_columns.issubset(info_columns):
            missing_in_info = data_columns - info_columns
            if missing_in_info:
                print(f"âš ï¸  è­¦å‘Š: æ•°æ®ä¸­çš„ä»¥ä¸‹åˆ—åœ¨åˆ—ä¿¡æ¯ä¸­æœªæ‰¾åˆ°: {missing_in_info}")
        
        return data, column_info
    
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æˆ–æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        sys.exit(1)
    except pd.errors.EmptyDataError:
        print("âŒ é”™è¯¯: æ•°æ®é›†æ–‡ä»¶ä¸ºç©º")
        sys.exit(1)
    except json.JSONDecodeError:
        print("âŒ é”™è¯¯: åˆ—ä¿¡æ¯æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")
        sys.exit(1)

def detect_and_handle_outliers(data, column_info, outliers_dir):
    """æ£€æµ‹å’Œå¤„ç†å¼‚å¸¸å€¼"""
    
    print("\n" + "=" * 60)
    print("å¼€å§‹å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†")
    print("=" * 60)
    
    # åˆ›å»ºå‰¯æœ¬ï¼Œä¸ä¿®æ”¹åŸå§‹æ•°æ®
    data_clean = data.copy()
    outlier_report = {
        'processing_steps': {},
        'summary': {},
        'detailed_stats': {}
    }
    
    # è®°å½•åŸå§‹æ•°æ®å½¢çŠ¶
    original_rows = data.shape[0]
    original_cols = data.shape[1]
    
    # ===============================
    # 1. ä¸šåŠ¡è§„åˆ™è¿‡æ»¤ï¼ˆç¡¬æ€§è§„åˆ™ï¼‰
    # ===============================
    
    print("\nğŸ“‹ æ­¥éª¤1: ä¸šåŠ¡è§„åˆ™è¿‡æ»¤")
    
    # 1.1 age: å¹´é¾„èŒƒå›´è¿‡æ»¤ï¼ˆ15-100å²ï¼‰
    if 'age' in data_clean.columns:
        age_mask = data_clean['age'].between(15, 100)
        age_outliers = data_clean[~age_mask].shape[0]
        data_clean = data_clean[age_mask]
        outlier_report['processing_steps']['age_business_rule'] = {
            'type': 'business_rule',
            'condition': 'age between 15 and 100',
            'records_removed': age_outliers
        }
        print(f"  âœ… age: åˆ é™¤ {age_outliers} æ¡è®°å½•ï¼ˆå¹´é¾„<15æˆ–>100ï¼‰")
    
    # 1.2 balance: è´¦æˆ·ä½™é¢èŒƒå›´ï¼ˆé¿å…æç«¯å€¼å½±å“ï¼‰
    if 'balance' in data_clean.columns:
        balance_mask = data_clean['balance'].between(-100000, 1000000)
        balance_outliers = data_clean[~balance_mask].shape[0]
        data_clean = data_clean[balance_mask]
        outlier_report['processing_steps']['balance_business_rule'] = {
            'type': 'business_rule',
            'condition': 'balance between -100,000 and 1,000,000',
            'records_removed': balance_outliers
        }
        print(f"  âœ… balance: åˆ é™¤ {balance_outliers} æ¡è®°å½•ï¼ˆä½™é¢<-100,000æˆ–>1,000,000ï¼‰")
    
    # 1.3 duration: é€šè¯æ—¶é•¿å¿…é¡»éè´Ÿ
    if 'duration' in data_clean.columns:
        duration_mask = data_clean['duration'] >= 0
        duration_outliers = data_clean[~duration_mask].shape[0]
        data_clean = data_clean[duration_mask]
        outlier_report['processing_steps']['duration_business_rule'] = {
            'type': 'business_rule',
            'condition': 'duration >= 0',
            'records_removed': duration_outliers
        }
        print(f"  âœ… duration: åˆ é™¤ {duration_outliers} æ¡è®°å½•ï¼ˆé€šè¯æ—¶é•¿<0ï¼‰")
    
    # 1.4 campaign: å½“å‰è¥é”€è”ç³»æ¬¡æ•°å¿…é¡»ä¸ºæ­£æ•°
    if 'campaign' in data_clean.columns:
        campaign_mask = data_clean['campaign'] > 0
        campaign_outliers = data_clean[~campaign_mask].shape[0]
        data_clean = data_clean[campaign_mask]
        outlier_report['processing_steps']['campaign_business_rule'] = {
            'type': 'business_rule',
            'condition': 'campaign > 0',
            'records_removed': campaign_outliers
        }
        print(f"  âœ… campaign: åˆ é™¤ {campaign_outliers} æ¡è®°å½•ï¼ˆè¥é”€æ¬¡æ•°â‰¤0ï¼‰")
    
    # 1.5 pdays: ä¸Šä¸€æ¬¡è”ç³»çš„å¤©æ•°ï¼ˆç‰¹æ®Šå€¼-1è¡¨ç¤ºæœªè”ç³»è¿‡ï¼‰
    if 'pdays' in data_clean.columns:
        # pdaysçš„ç‰¹æ®Šæƒ…å†µï¼š-1è¡¨ç¤ºä»æœªè”ç³»
        pdays_mask = data_clean['pdays'] >= -1
        pdays_outliers = data_clean[~pdays_mask].shape[0]
        data_clean = data_clean[pdays_mask]
        outlier_report['processing_steps']['pdays_business_rule'] = {
            'type': 'business_rule',
            'condition': 'pdays >= -1',
            'records_removed': pdays_outliers
        }
        print(f"  âœ… pdays: åˆ é™¤ {pdays_outliers} æ¡è®°å½•ï¼ˆpdays < -1ï¼‰")
    
    # 1.6 previous: ä¹‹å‰è”ç³»æ¬¡æ•°å¿…é¡»éè´Ÿ
    if 'previous' in data_clean.columns:
        previous_mask = data_clean['previous'] >= 0
        previous_outliers = data_clean[~previous_mask].shape[0]
        data_clean = data_clean[previous_mask]
        outlier_report['processing_steps']['previous_business_rule'] = {
            'type': 'business_rule',
            'condition': 'previous >= 0',
            'records_removed': previous_outliers
        }
        print(f"  âœ… previous: åˆ é™¤ {previous_outliers} æ¡è®°å½•ï¼ˆä¹‹å‰è”ç³»æ¬¡æ•°<0ï¼‰")
    
    # 1.7 day: æ—¥æœŸå¿…é¡»åœ¨1-31ä¹‹é—´
    if 'day' in data_clean.columns:
        day_mask = data_clean['day'].between(1, 31)
        day_outliers = data_clean[~day_mask].shape[0]
        data_clean = data_clean[day_mask]
        outlier_report['processing_steps']['day_business_rule'] = {
            'type': 'business_rule',
            'condition': 'day between 1 and 31',
            'records_removed': day_outliers
        }
        print(f"  âœ… day: åˆ é™¤ {day_outliers} æ¡è®°å½•ï¼ˆæ—¥æœŸ<1æˆ–>31ï¼‰")
    
    # ===============================
    # 2. ç»Ÿè®¡æˆªæ–­å¤„ç†ï¼ˆWinsorizationï¼‰
    # ===============================
    
    print("\nğŸ“ˆ æ­¥éª¤2: ç»Ÿè®¡æˆªæ–­å¤„ç†ï¼ˆæ¸©å’Œå¤„ç†ï¼‰")
    # é€‰æ‹©éœ€è¦è¿›è¡Œç¼©å°¾å¤„ç†çš„æ•°å€¼åˆ—
    numerical_cols_for_winsor = ['balance', 'duration', 'campaign', 'pdays', 'previous']
    
    for col in numerical_cols_for_winsor:
        if col in data_clean.columns:
            try:
                # è®¡ç®—1%å’Œ99%åˆ†ä½æ•°
                q1 = data_clean[col].quantile(0.01)
                q99 = data_clean[col].quantile(0.99)
                
                # ç»Ÿè®¡æˆªæ–­å‰çš„å¼‚å¸¸å€¼æ•°é‡
                before_outliers = data_clean[(data_clean[col] < q1) | (data_clean[col] > q99)].shape[0]
                
                if before_outliers > 0:
                    # åº”ç”¨Winsorizationï¼šå°†æç«¯å€¼ç¼©å°¾
                    clipped_col = np.clip(data_clean[col], q1, q99)
                    data_clean[col] = clipped_col
                    
                    outlier_report['processing_steps'][f'{col}_winsorization'] = {
                        'type': 'winsorization',
                        'lower_bound': float(q1),
                        'upper_bound': float(q99),
                        'records_affected': int(before_outliers)
                    }
                    print(f"  âœ… {col}: ç¼©å°¾å¤„ç† {before_outliers} ä¸ªæç«¯å€¼ï¼ˆ1%-99%èŒƒå›´ï¼‰")
                    print(f"     ä¸‹ç•Œ: {q1:.2f}, ä¸Šç•Œ: {q99:.2f}")
            except Exception as e:
                print(f"  âš ï¸  {col}: å¤„ç†å¤±è´¥ - {e}")
    
    # ===============================
    # 3. ç›®æ ‡å˜é‡æ£€æŸ¥
    # ===============================
    
    print("\nğŸ¯ æ­¥éª¤3: ç›®æ ‡å˜é‡æ£€æŸ¥")
    if 'deposit' in data_clean.columns:
        unique_values = sorted(data_clean['deposit'].unique())
        print(f"  deposit çš„å”¯ä¸€å€¼: {unique_values}")
        
        # è®°å½•ç›®æ ‡å˜é‡ä¿¡æ¯
        deposit_counts = data_clean['deposit'].value_counts().to_dict()
        outlier_report['target_variable'] = {
            'unique_values': [int(val) for val in unique_values],
            'value_counts': {int(k): int(v) for k, v in deposit_counts.items()}
        }
        
        print(f"  ç›®æ ‡å˜é‡åˆ†å¸ƒ:")
        total = len(data_clean)
        for val, count in data_clean['deposit'].value_counts().items():
            percentage = count / total * 100
            print(f"    {val}: {count:,} ({percentage:.1f}%)")
    else:
        print("  âš ï¸  æœªæ‰¾åˆ°ç›®æ ‡å˜é‡ 'deposit'")
    
    # ===============================
    # 4. ç±»åˆ«å˜é‡æ£€æŸ¥
    # ===============================
    
    print("\nğŸ“Š æ­¥éª¤4: ç±»åˆ«å˜é‡æ£€æŸ¥")
    categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month']
    
    category_report = {}
    for col in categorical_cols:
        if col in data_clean.columns:
            if col in column_info['columns']:
                try:
                    expected_values = column_info['columns'][col]['values']
                    actual_values = list(data_clean[col].astype(str).unique())
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ„å¤–å€¼
                    unexpected = list(set(actual_values) - set(expected_values))
                    
                    category_report[col] = {
                        'expected_values': expected_values,
                        'actual_values': actual_values,
                        'unexpected_values': unexpected,
                        'has_unexpected': len(unexpected) > 0
                    }
                    
                    if unexpected:
                        print(f"  âš ï¸  {col}: å‘ç°æ„å¤–å€¼ {unexpected[:5]}")  # åªæ˜¾ç¤ºå‰5ä¸ª
                    else:
                        print(f"  âœ… {col}: æ‰€æœ‰å€¼éƒ½åœ¨é¢„æœŸèŒƒå›´å†…")
                except Exception as e:
                    print(f"  âŒ {col}: æ£€æŸ¥å¤±è´¥ - {e}")
            else:
                print(f"  âš ï¸  {col}: æœªåœ¨åˆ—ä¿¡æ¯ä¸­æ‰¾åˆ°")
    
    outlier_report['categorical_check'] = category_report
    
    # ===============================
    # 5. æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯
    # ===============================
    
    cleaned_rows = data_clean.shape[0]
    rows_removed = original_rows - cleaned_rows
    retention_rate = cleaned_rows / original_rows * 100
    
    # è®°å½•è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯
    outlier_report['summary'] = {
        'original_rows': original_rows,
        'original_columns': original_cols,
        'cleaned_rows': cleaned_rows,
        'cleaned_columns': data_clean.shape[1],
        'rows_removed': rows_removed,
        'retention_rate': retention_rate,
        'removal_rate': 100 - retention_rate
    }
    
    # æ•°å€¼ç‰¹å¾çš„æè¿°æ€§ç»Ÿè®¡
    numerical_cols = [col for col in data_clean.columns 
                     if column_info['columns'][col]['type'] == 'numerical' 
                     if col in column_info['columns']]
    
    descriptive_stats = {}
    for col in numerical_cols:
        if col in data_clean.columns:
            stats = data_clean[col].describe().to_dict()
            descriptive_stats[col] = {
                'mean': float(stats.get('mean', 0)),
                'std': float(stats.get('std', 0)),
                'min': float(stats.get('min', 0)),
                '25%': float(stats.get('25%', 0)),
                '50%': float(stats.get('50%', 0)),
                '75%': float(stats.get('75%', 0)),
                'max': float(stats.get('max', 0))
            }
    
    outlier_report['descriptive_statistics'] = descriptive_stats
    
    # ===============================
    # 6. ç»“æœå±•ç¤º
    # ===============================
    
    print("\n" + "=" * 60)
    print("âœ… å¼‚å¸¸å€¼å¤„ç†å®Œæˆï¼")
    print("=" * 60)
    print(f"ğŸ“Š å¤„ç†æ‘˜è¦:")
    print(f"   åŸå§‹æ•°æ®è¡Œæ•°: {original_rows:,}")
    print(f"   å¤„ç†åæ•°æ®è¡Œæ•°: {cleaned_rows:,}")
    print(f"   åˆ é™¤çš„è¡Œæ•°: {rows_removed:,}")
    print(f"   æ•°æ®ä¿ç•™æ¯”ä¾‹: {retention_rate:.1f}%")
    print(f"   åˆ é™¤æ¯”ä¾‹: {100 - retention_rate:.1f}%")
    print(f"   æ•°æ®å½¢çŠ¶å˜åŒ–: {original_rows}Ã—{original_cols} â†’ {cleaned_rows}Ã—{data_clean.shape[1]}")
    
    return data_clean, outlier_report

def visualize_outliers(data_before, data_after, outliers_dir):
    """å¯è§†åŒ–å¤„ç†å‰åçš„å¼‚å¸¸å€¼å˜åŒ–"""
    # æ•°å€¼ç‰¹å¾åˆ—è¡¨ï¼ˆä»…æ˜¾ç¤ºæœ‰å¼‚å¸¸å€¼çš„ç‰¹å¾ï¼‰
    numerical_cols = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']
    
    # åˆ›å»ºå­å›¾
    fig, axes = plt.subplots(len(numerical_cols), 2, figsize=(16, 5*len(numerical_cols)))
    fig.suptitle('å¼‚å¸¸å€¼å¤„ç†å‰åå¯¹æ¯”', fontsize=16, y=1.02)
    
    for idx, col in enumerate(numerical_cols):
        if col not in data_before.columns or col not in data_after.columns:
            continue
        
        # å¤„ç†å‰çš„ç®±çº¿å›¾
        ax1 = axes[idx, 0]
        bp1 = ax1.boxplot(data_before[col].dropna(), vert=True, patch_artist=True)
        # è®¾ç½®é¢œè‰²
        bp1['boxes'][0].set_facecolor('lightcoral')
        ax1.set_title(f'{col} - å¤„ç†å‰', fontsize=12, fontweight='bold')
        ax1.set_ylabel('æ•°å€¼')
        ax1.grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_before = data_before[col].describe()
        text1 = f"å‡å€¼: {stats_before['mean']:.2f}\næ ‡å‡†å·®: {stats_before['std']:.2f}\nå¼‚å¸¸å€¼: {len([x for x in data_before[col] if x < stats_before['25%'] - 1.5*(stats_before['75%']-stats_before['25%']) or x > stats_before['75%'] + 1.5*(stats_before['75%']-stats_before['25%'])])}"
        ax1.text(0.02, 0.98, text1, transform=ax1.transAxes, 
                fontsize=9, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        # å¤„ç†åçš„ç®±çº¿å›¾  
        ax2 = axes[idx, 1]
        bp2 = ax2.boxplot(data_after[col].dropna(), vert=True, patch_artist=True)
        bp2['boxes'][0].set_facecolor('lightgreen')
        ax2.set_title(f'{col} - å¤„ç†å', fontsize=12, fontweight='bold')
        ax2.set_ylabel('æ•°å€¼')
        ax2.grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_after = data_after[col].describe()
        text2 = f"å‡å€¼: {stats_after['mean']:.2f}\næ ‡å‡†å·®: {stats_after['std']:.2f}\nå¼‚å¸¸å€¼: {len([x for x in data_after[col] if x < stats_after['25%'] - 1.5*(stats_after['75%']-stats_after['25%']) or x > stats_after['75%'] + 1.5*(stats_after['75%']-stats_after['25%'])])}"
        ax2.text(0.02, 0.98, text2, transform=ax2.transAxes, 
                fontsize=9, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    output_path = os.path.join(outliers_dir, 'outlier_handling_comparison.png')
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"\nğŸ“ˆ å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")
    plt.show()
    
    # å•ç‹¬ç»˜åˆ¶balanceï¼ˆé€šå¸¸å¼‚å¸¸å€¼æœ€å¤šï¼‰
    if 'balance' in data_before.columns and 'balance' in data_after.columns:
        fig2, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
        fig2.suptitle('è´¦æˆ·ä½™é¢å¼‚å¸¸å€¼å¤„ç†å¯¹æ¯”', fontsize=14)
        
        # å¤„ç†å‰
        bp1 = ax1.boxplot(data_before['balance'].dropna(), vert=True, patch_artist=True)
        bp1['boxes'][0].set_facecolor('lightcoral')
        ax1.set_title('å¤„ç†å‰', fontsize=12)
        ax1.set_ylabel('ä½™é¢')
        ax1.grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_before = data_before['balance'].describe()
        outliers_before = len([x for x in data_before['balance'] 
                              if x < stats_before['25%'] - 1.5*(stats_before['75%']-stats_before['25%']) 
                              or x > stats_before['75%'] + 1.5*(stats_before['75%']-stats_before['25%'])])
        ax1.text(0.05, 0.95, f"å¼‚å¸¸å€¼æ•°é‡: {outliers_before:,}", 
                transform=ax1.transAxes, fontsize=10,
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        # å¤„ç†å
        bp2 = ax2.boxplot(data_after['balance'].dropna(), vert=True, patch_artist=True)
        bp2['boxes'][0].set_facecolor('lightgreen')
        ax2.set_title('å¤„ç†å', fontsize=12)
        ax2.set_ylabel('ä½™é¢')
        ax2.grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_after = data_after['balance'].describe()
        outliers_after = len([x for x in data_after['balance'] 
                             if x < stats_after['25%'] - 1.5*(stats_after['75%']-stats_after['25%']) 
                             or x > stats_after['75%'] + 1.5*(stats_after['75%']-stats_after['25%'])])
        ax2.text(0.05, 0.95, f"å¼‚å¸¸å€¼æ•°é‡: {outliers_after:,}", 
                transform=ax2.transAxes, fontsize=10,
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        output_path2 = os.path.join(outliers_dir, 'balance_outlier_comparison.png')
        plt.savefig(output_path2, dpi=150, bbox_inches='tight')
        print(f"ğŸ“ˆ Balanceå¯¹æ¯”å›¾å·²ä¿å­˜: {output_path2}")
        plt.show()

def save_results(data_clean, outlier_report, outliers_dir, column_info):
    """ä¿å­˜å¤„ç†ç»“æœ"""
    
    print("\nğŸ’¾ å¼€å§‹ä¿å­˜å¤„ç†ç»“æœ...")
    
    # 1. ä¿å­˜æ¸…ç†åçš„æ•°æ®
    output_data_path = os.path.join(outliers_dir, 'bank_marketing_outliers_cleaned.csv')
    data_clean.to_csv(output_data_path, index=False)
    print(f"âœ… æ¸…ç†åçš„æ•°æ®å·²ä¿å­˜: {output_data_path}")
    print(f"   æ–‡ä»¶å¤§å°: {os.path.getsize(output_data_path) / 1024:.1f} KB")
    
    # 2. ä¿å­˜å¼‚å¸¸å€¼å¤„ç†æŠ¥å‘Šï¼ˆè¯¦ç»†ç‰ˆï¼‰
    report_path = os.path.join(outliers_dir, 'outlier_handling_report.json')
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(outlier_report, f, indent=2, ensure_ascii=False)
    print(f"âœ… è¯¦ç»†å¤„ç†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    # 3. ä¿å­˜å¼‚å¸¸å€¼å¤„ç†æŠ¥å‘Šï¼ˆç®€ç‰ˆï¼‰
    summary_report = {
        'åŸºæœ¬ä¿¡æ¯': {
            'åŸå§‹æ•°æ®è¡Œæ•°': outlier_report['summary']['original_rows'],
            'å¤„ç†åæ•°æ®è¡Œæ•°': outlier_report['summary']['cleaned_rows'],
            'åˆ é™¤è¡Œæ•°': outlier_report['summary']['rows_removed'],
            'ä¿ç•™æ¯”ä¾‹(%)': round(outlier_report['summary']['retention_rate'], 2),
            'åˆ é™¤æ¯”ä¾‹(%)': round(outlier_report['summary']['removal_rate'], 2)
        },
        'å¤„ç†æ­¥éª¤': {
            'ä¸šåŠ¡è§„åˆ™è¿‡æ»¤': {},
            'ç»Ÿè®¡ç¼©å°¾å¤„ç†': {}
        }
    }
    
    # ä»è¯¦ç»†æŠ¥å‘Šä¸­æå–å…³é”®ä¿¡æ¯åˆ°ç®€ç‰ˆ
    for key, value in outlier_report['processing_steps'].items():
        if 'business_rule' in key:
            col_name = key.replace('_business_rule', '')
            summary_report['å¤„ç†æ­¥éª¤']['ä¸šåŠ¡è§„åˆ™è¿‡æ»¤'][col_name] = {
                'åˆ é™¤è®°å½•æ•°': value['records_removed']
            }
        elif 'winsorization' in key:
            col_name = key.replace('_winsorization', '')
            summary_report['å¤„ç†æ­¥éª¤']['ç»Ÿè®¡ç¼©å°¾å¤„ç†'][col_name] = {
                'å½±å“è®°å½•æ•°': value['records_affected'],
                'ä¸‹ç•Œ': value['lower_bound'],
                'ä¸Šç•Œ': value['upper_bound']
            }
    
    # ç›®æ ‡å˜é‡ä¿¡æ¯
    if 'target_variable' in outlier_report:
        summary_report['ç›®æ ‡å˜é‡'] = outlier_report['target_variable']
    
    summary_path = os.path.join(outliers_dir, 'outlier_handling_summary.json')
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary_report, f, indent=2, ensure_ascii=False)
    print(f"âœ… ç®€æ´å¤„ç†æ€»ç»“å·²ä¿å­˜: {summary_path}")
    
    # 4. ä¿å­˜å¤„ç†åçš„æ•°æ®æè¿°æ€§ç»Ÿè®¡
    descriptive_stats = outlier_report.get('descriptive_statistics', {})
    if descriptive_stats:
        stats_df = pd.DataFrame(descriptive_stats).T
        stats_csv_path = os.path.join(outliers_dir, 'descriptive_statistics_after_outliers.csv')
        stats_df.to_csv(stats_csv_path)
        print(f"âœ… æè¿°æ€§ç»Ÿè®¡å·²ä¿å­˜: {stats_csv_path}")
    
    # 5. ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
    txt_report_path = os.path.join(outliers_dir, 'outlier_handling_summary.txt')
    with open(txt_report_path, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("             å¼‚å¸¸å€¼å¤„ç†æ€»ç»“æŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")
        
        f.write("1. æ•°æ®æ¦‚å†µ\n")
        f.write("-" * 40 + "\n")
        f.write(f"åŸå§‹æ•°æ®å½¢çŠ¶: {outlier_report['summary']['original_rows']} è¡Œ Ã— {outlier_report['summary']['original_columns']} åˆ—\n")
        f.write(f"å¤„ç†åæ•°æ®å½¢çŠ¶: {outlier_report['summary']['cleaned_rows']} è¡Œ Ã— {outlier_report['summary']['cleaned_columns']} åˆ—\n")
        f.write(f"åˆ é™¤è®°å½•æ•°: {outlier_report['summary']['rows_removed']}\n")
        f.write(f"æ•°æ®ä¿ç•™ç‡: {outlier_report['summary']['retention_rate']:.2f}%\n\n")
        
        f.write("2. ä¸šåŠ¡è§„åˆ™è¿‡æ»¤ç»“æœ\n")
        f.write("-" * 40 + "\n")
        for key, value in outlier_report['processing_steps'].items():
            if 'business_rule' in key:
                col_name = key.replace('_business_rule', '')
                f.write(f"  {col_name}: åˆ é™¤ {value['records_removed']} æ¡è®°å½•\n")
        
        f.write("\n3. ç»Ÿè®¡ç¼©å°¾å¤„ç†ç»“æœ\n")
        f.write("-" * 40 + "\n")
        for key, value in outlier_report['processing_steps'].items():
            if 'winsorization' in key:
                col_name = key.replace('_winsorization', '')
                f.write(f"  {col_name}: å¤„ç† {value['records_affected']} ä¸ªæç«¯å€¼ ({value['lower_bound']:.2f} - {value['upper_bound']:.2f})\n")
        
        f.write("\n4. ç›®æ ‡å˜é‡åˆ†å¸ƒ\n")
        f.write("-" * 40 + "\n")
        if 'target_variable' in outlier_report:
            total = sum(outlier_report['target_variable']['value_counts'].values())
            for val, count in outlier_report['target_variable']['value_counts'].items():
                percentage = count / total * 100
                f.write(f"  {val}: {count} ({percentage:.1f}%)\n")
        
        f.write("\n" + "=" * 80 + "\n")
        f.write("å¤„ç†å®Œæˆæ—¶é—´: " + pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S") + "\n")
        f.write("=" * 80 + "\n")
    
    print(f"âœ… æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜: {txt_report_path}")
    
    return {
        'cleaned_data_path': output_data_path,
        'detailed_report_path': report_path,
        'summary_report_path': summary_path,
        'text_report_path': txt_report_path
    }

def generate_readme(outliers_dir, file_paths):
    """ç”ŸæˆREADMEæ–‡ä»¶ï¼Œè¯´æ˜å¤„ç†è¿‡ç¨‹å’Œç»“æœ"""
    readme_path = os.path.join(outliers_dir, 'README.md')
    
    readme_content = """# å¼‚å¸¸å€¼å¤„ç†è®°å½•

## ğŸ“‹ å¤„ç†æ¦‚è¿°
æœ¬æ–‡ä»¶å¤¹åŒ…å«äº†é“¶è¡Œè¥é”€æ•°æ®é›†çš„å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†ç»“æœã€‚

## ğŸš€ å¤„ç†æ–¹æ³•
é‡‡ç”¨äº†ä¸¤ç§ä¸»è¦çš„å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥ï¼š

### 1. ä¸šåŠ¡è§„åˆ™è¿‡æ»¤
åŸºäºä¸šåŠ¡çŸ¥è¯†è®¾å®šåˆç†çš„å€¼åŸŸèŒƒå›´ï¼š
- **å¹´é¾„ (age)**: 15-100å²
- **ä½™é¢ (balance)**: -100,000 ~ 1,000,000
- **é€šè¯æ—¶é•¿ (duration)**: â‰¥0
- **å½“å‰è”ç³»æ¬¡æ•° (campaign)**: >0
- **ä¸Šæ¬¡è”ç³»å¤©æ•° (pdays)**: â‰¥-1 (-1è¡¨ç¤ºæœªè”ç³»è¿‡)
- **ä¹‹å‰è”ç³»æ¬¡æ•° (previous)**: â‰¥0
- **æ—¥æœŸ (day)**: 1-31

è¶…å‡ºä¸Šè¿°èŒƒå›´çš„è®°å½•è¢«ç›´æ¥åˆ é™¤ã€‚

### 2. ç»Ÿè®¡ç¼©å°¾å¤„ç†ï¼ˆWinsorizationï¼‰
å¯¹ä»¥ä¸‹ç‰¹å¾çš„æç«¯å€¼è¿›è¡Œç¼©å°¾å¤„ç†ï¼š
- balance, duration, campaign, pdays, previous

å¤„ç†æ–¹å¼ï¼šå°†å°äº1%åˆ†ä½æ•°å’Œå¤§äº99%åˆ†ä½æ•°çš„å€¼æˆªæ–­åˆ°ç›¸åº”è¾¹ç•Œã€‚

## ğŸ“ æ–‡ä»¶è¯´æ˜

### ä¸»è¦æ–‡ä»¶
| æ–‡ä»¶åç§° | è¯´æ˜ |
|----------|------|
| `bank_marketing_outliers_cleaned.csv` | å¤„ç†åçš„å®Œæ•´æ•°æ®é›† |
| `outlier_handling_report.json` | è¯¦ç»†çš„å¤„ç†æŠ¥å‘Šï¼ˆJSONæ ¼å¼ï¼‰ |
| `outlier_handling_summary.json` | ç®€æ´çš„å¤„ç†æ€»ç»“æŠ¥å‘Š |
| `outlier_handling_summary.txt` | æ–‡æœ¬æ ¼å¼çš„å¤„ç†æ€»ç»“ |

### å¯è§†åŒ–æ–‡ä»¶
| æ–‡ä»¶åç§° | è¯´æ˜ |
|----------|------|
| `outlier_handling_comparison.png` | æ‰€æœ‰æ•°å€¼ç‰¹å¾å¤„ç†å‰åå¯¹æ¯”å›¾ |
| `balance_outlier_comparison.png` | è´¦æˆ·ä½™é¢çš„è¯¦ç»†å¯¹æ¯”å›¾ |

### ç»Ÿè®¡æ–‡ä»¶
| æ–‡ä»¶åç§° | è¯´æ˜ |
|----------|------|
| `descriptive_statistics_after_outliers.csv` | å¤„ç†åæ•°å€¼ç‰¹å¾çš„æè¿°æ€§ç»Ÿè®¡ |

## ğŸ”§ ä½¿ç”¨è¯´æ˜
1. ä¸»è¦åˆ†ææ•°æ®ï¼šä½¿ç”¨ `bank_marketing_outliers_cleaned.csv`
2. æŸ¥çœ‹å¤„ç†è¯¦æƒ…ï¼šæŸ¥çœ‹ `outlier_handling_summary.json` æˆ– `outlier_handling_summary.txt`
3. å¯è§†åŒ–ç»“æœï¼šæŸ¥çœ‹ `.png` æ ¼å¼çš„å¯¹æ¯”å›¾
4. å¦‚éœ€å¤ç°å¤„ç†è¿‡ç¨‹ï¼Œå‚è€ƒè¯¦ç»†æŠ¥å‘Š `outlier_handling_report.json`

## ğŸ“Š å…³é”®æŒ‡æ ‡
å¤„ç†å‰åçš„å…³é”®æŒ‡æ ‡å¯¹æ¯”å¯å‚è€ƒæ–‡æœ¬æŠ¥å‘Šæˆ–JSONæ€»ç»“æ–‡ä»¶ã€‚

---

*ç”Ÿæˆæ—¶é—´ï¼š""" + pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S") + "*"

    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"ğŸ“˜ READMEæ–‡ä»¶å·²ç”Ÿæˆ: {readme_path}")
    return readme_path

def show_final_data_preview(data_clean, column_info):
    """æ˜¾ç¤ºæœ€ç»ˆæ•°æ®é¢„è§ˆ"""
    print("\n" + "=" * 60)
    print("ğŸ“Š æœ€ç»ˆæ•°æ®é›†é¢„è§ˆ")
    print("=" * 60)
    
    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
    print(f"æ•°æ®å½¢çŠ¶: {data_clean.shape[0]:,} è¡Œ Ã— {data_clean.shape[1]} åˆ—")
    print(f"å†…å­˜ä½¿ç”¨: {data_clean.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
    
    # æ˜¾ç¤ºåˆ—ä¿¡æ¯
    print("\næ•°æ®åˆ—:")
    for i, col in enumerate(data_clean.columns, 1):
        col_type = column_info['columns'][col]['type'] if col in column_info['columns'] else 'unknown'
        unique_count = data_clean[col].nunique()
        print(f"  {i:2d}. {col:<15} ({col_type:<12}) - {unique_count} ä¸ªå”¯ä¸€å€¼")
    
    # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
    print("\nå‰5è¡Œæ•°æ®:")
    print(data_clean.head())
    
    # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    print("\næ•°å€¼ç‰¹å¾çš„æè¿°æ€§ç»Ÿè®¡:")
    numerical_cols = [col for col in data_clean.columns 
                     if column_info['columns'][col]['type'] == 'numerical' 
                     if col in column_info['columns']]
    
    if numerical_cols:
        stats_df = data_clean[numerical_cols].describe().round(2)
        print(stats_df)

# ===============================
# ä¸»ç¨‹åºï¼šæ‰§è¡Œå¼‚å¸¸å€¼å¤„ç†
# ===============================
if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹è¿è¡Œå¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†ç¨‹åº")
    print("=" * 60)
    try:
        import matplotlib
        matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
        matplotlib.rcParams['axes.unicode_minus'] = False
    except:
        pass
    
    try:
        # 1. åˆ›å»ºç›®å½•
        print("\nğŸ“‚ æ­¥éª¤1: åˆ›å»ºè¾“å‡ºç›®å½•")
        outliers_dir = create_directories()
        
        # 2. åŠ è½½æ•°æ®
        print("\nğŸ“‚ æ­¥éª¤2: åŠ è½½æ•°æ®")
        data, column_info = load_data_and_info()
        
        # 3. å¤‡ä»½åŸå§‹æ•°æ®ç”¨äºå¯è§†åŒ–å¯¹æ¯”
        data_before = data.copy()
        
        # 4. æ£€æµ‹å’Œå¤„ç†å¼‚å¸¸å€¼
        print("\nğŸ”§ æ­¥éª¤3: å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†")
        data_clean, outlier_report = detect_and_handle_outliers(data, column_info, outliers_dir)
        
        # 5. å¯è§†åŒ–æ¯”è¾ƒ
        print("\nğŸ“Š æ­¥éª¤4: ç”Ÿæˆå¯è§†åŒ–å¯¹æ¯”")
        visualize_outliers(data_before, data_clean, outliers_dir)
        
        # 6. ä¿å­˜ç»“æœ
        print("\nğŸ’¾ æ­¥éª¤5: ä¿å­˜å¤„ç†ç»“æœ")
        file_paths = save_results(data_clean, outlier_report, outliers_dir, column_info)
        
        # 7. ç”ŸæˆREADME
        print("\nğŸ“˜ æ­¥éª¤6: ç”Ÿæˆè¯´æ˜æ–‡æ¡£")
        readme_path = generate_readme(outliers_dir, file_paths)
        
        # 8. æ˜¾ç¤ºæœ€ç»ˆæ•°æ®é¢„è§ˆ
        print("\nğŸ‘€ æ­¥éª¤7: æ˜¾ç¤ºæœ€ç»ˆæ•°æ®é¢„è§ˆ")
        show_final_data_preview(data_clean, column_info)
        
        # 9. å®Œæˆ
        print("\n" + "=" * 60)
        print("ğŸ‰ å¼‚å¸¸å€¼å¤„ç†æµç¨‹å®Œæˆï¼")
        print("=" * 60)
        print(f"\nğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åœ¨: {outliers_dir}")
        print(f"\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
        for file_name in os.listdir(outliers_dir):
            file_path = os.path.join(outliers_dir, file_name)
            file_size = os.path.getsize(file_path) / 1024
            print(f"  â€¢ {file_name:<40} ({file_size:.1f} KB)")
        
        print(f"\nâœ… æµç¨‹å®Œæˆï¼æ¸…ç†åçš„æ•°æ®å·²å‡†å¤‡å¥½ç”¨äºåç»­åˆ†æã€‚")
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
