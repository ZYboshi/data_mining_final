# basic_analysis_final.py
"""
åŸºç¡€ç»Ÿè®¡åˆ†æ - æœ€ç»ˆç‰ˆ
æ‰€æœ‰ç»“æœå­˜å‚¨åœ¨ ./preprocess_dataset/basic_data_analysis æ–‡ä»¶å¤¹
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import os
import warnings
warnings.filterwarnings('ignore')

class BasicDataAnalysis:
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æç±»ï¼Œè®¾ç½®è¾“å‡ºè·¯å¾„"""
        # è®¾ç½®ä¸»è¾“å‡ºæ–‡ä»¶å¤¹
        self.output_dir = './preprocess_dataset/basic_data_analysis'
        
        # åˆ›å»ºæ–‡ä»¶å¤¹ç»“æ„
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, 'figures'), exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, 'tables'), exist_ok=True)
        
        print(f"ğŸ“ æ‰€æœ‰åˆ†æç»“æœå°†ä¿å­˜åˆ°: {self.output_dir}")
    
    def load_data(self):
        """åŠ è½½æ•°æ®é›†"""
        # æŸ¥æ‰¾æ•°æ®æ–‡ä»¶çš„ä¼˜å…ˆçº§
        possible_paths = [
            './preprocess_dataset/bank_marketing_renamed.csv',  # ä¼˜å…ˆä½¿ç”¨é¢„å¤„ç†æ–‡ä»¶
            './dataset/bank_marketing_renamed.csv',
            './dataset/bank_marketing.csv'
        ]
        
        data = None
        data_path = None
        
        for path in possible_paths:
            if os.path.exists(path):
                print(f"âœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {path}")
                data_path = path
                break
        
        if data_path is None:
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•æ•°æ®æ–‡ä»¶")
            print("è¯·å…ˆè¿è¡Œ data_process.py æˆ–ç¡®ä¿æœ‰ä»¥ä¸‹æ–‡ä»¶ä¹‹ä¸€:")
            for path in possible_paths:
                print(f"  - {path}")
            return None
        
        # åŠ è½½æ•°æ®
        data = pd.read_csv(data_path)
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {data.shape[0]}è¡Œ Ã— {data.shape[1]}åˆ—")
        
        # å¦‚æœåŠ è½½çš„æ˜¯åŸå§‹æ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦é‡å‘½å
        if 'bank_marketing.csv' in data_path:
            print("æ£€æµ‹åˆ°åŸå§‹æ•°æ®ï¼Œå°è¯•é‡å‘½ååˆ—...")
            
            # æŸ¥æ‰¾ç›®æ ‡åˆ—
            if 'Class' in data.columns:
                target_col_name = 'Class'
            else:
                target_col_name = 'deposit'
            
            # åˆ›å»ºåˆ—åæ˜ å°„
            column_mapping = {}
            for i, col in enumerate(data.columns):
                if col == target_col_name:
                    column_mapping[col] = 'deposit'
                elif col.startswith('V'):
                    num = int(col[1:]) if col[1:].isdigit() else i
                    standard_names = [
                        'age', 'job', 'marital', 'education', 'default',
                        'balance', 'housing', 'loan', 'contact', 'day',
                        'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome'
                    ]
                    if num <= len(standard_names):
                        column_mapping[col] = standard_names[num-1]
                else:
                    column_mapping[col] = col
            
            # åº”ç”¨é‡å‘½å
            data = data.rename(columns=column_mapping)
        
        return data
    
    def get_basic_stats(self, data):
        """è·å–åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*50)
        print("ğŸ“Š åŸºç¡€ç»Ÿè®¡ä¿¡æ¯")
        print("="*50)
        
        # 1. æ•°æ®é›†è§„æ¨¡
        stats = {
            "dataset_info": {
                "samples": int(data.shape[0]),
                "features": int(data.shape[1]),
                "columns": list(data.columns)
            }
        }
        
        print(f"ğŸ“¦ æ•°æ®é›†è§„æ¨¡: {stats['dataset_info']['samples']:,} æ ·æœ¬ Ã— {stats['dataset_info']['features']} ç‰¹å¾")
        
        # 2. æ•°æ®ç±»å‹åˆ†å¸ƒ
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = data.select_dtypes(include=['object']).columns.tolist()
        
        stats["data_type_distribution"] = {
            "numeric": {
                "count": len(numeric_cols),
                "percentage": round(len(numeric_cols) / data.shape[1] * 100, 1),
                "features": numeric_cols
            },
            "categorical": {
                "count": len(categorical_cols),
                "percentage": round(len(categorical_cols) / data.shape[1] * 100, 1),
                "features": categorical_cols
            }
        }
        
        print(f"ğŸ¨ æ•°æ®ç±»å‹åˆ†å¸ƒ:")
        print(f"  - æ•°å€¼å‹: {stats['data_type_distribution']['numeric']['count']}ä¸ª "
              f"({stats['data_type_distribution']['numeric']['percentage']}%)")
        print(f"  - ç±»åˆ«å‹: {stats['data_type_distribution']['categorical']['count']}ä¸ª "
              f"({stats['data_type_distribution']['categorical']['percentage']}%)")
        
        # 3. ç›®æ ‡å˜é‡åˆ†å¸ƒ
        target_candidates = ['deposit', 'Class', 'class', 'target', 'y']
        target_col = None
        
        for candidate in target_candidates:
            if candidate in data.columns:
                target_col = candidate
                break
        
        if target_col:
            stats["target_info"] = {
                "column_name": target_col,
                "data_type": str(data[target_col].dtype)
            }
            
            counts = data[target_col].value_counts()
            percentages = (data[target_col].value_counts(normalize=True) * 100).round(2)
            
            stats["target_distribution"] = {}
            for val in counts.index:
                stats["target_distribution"][str(val)] = {
                    "count": int(counts[val]),
                    "percentage": float(percentages[val]),
                    "label": str(val)
                }
            
            print(f"\nğŸ¯ ç›®æ ‡å˜é‡ '{target_col}' åˆ†å¸ƒ:")
            for val, cnt in counts.items():
                pct = percentages[val]
                print(f"  - {val}: {cnt:,} ä¸ª ({pct}%)")
            
            # è®¡ç®—ä¸å¹³è¡¡æ¯”ä¾‹ï¼ˆå¦‚æœæ˜¯äºŒåˆ†ç±»ï¼‰
            if len(counts) == 2:
                cnt_values = counts.values
                if cnt_values[0] > 0 and cnt_values[1] > 0:
                    ratio = max(cnt_values) / min(cnt_values)
                    stats["target_info"]["imbalance_ratio"] = float(ratio.round(2))
                    print(f"  âš ï¸  ç±»åˆ«ä¸å¹³è¡¡æ¯”ä¾‹: {ratio:.2f}:1")
        else:
            print(f"\nâš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°ç›®æ ‡å˜é‡åˆ—")
            stats["target_info"] = {"found": False}
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœä¸ºJSON
        stats_path = os.path.join(self.output_dir, 'tables', 'basic_statistics.json')
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {stats_path}")
        
        return stats
    
    def create_feature_type_chart(self, data):
        """åˆ›å»ºç‰¹å¾ç±»å‹åˆ†å¸ƒå›¾è¡¨"""
        numeric_count = len(data.select_dtypes(include=[np.number]).columns)
        categorical_count = len(data.select_dtypes(include=['object']).columns)
        
        # åˆ›å»ºé¥¼å›¾
        plt.figure(figsize=(10, 8))
        
        sizes = [numeric_count, categorical_count]
        labels = [f'æ•°å€¼å‹ ({numeric_count}ä¸ª)', f'ç±»åˆ«å‹ ({categorical_count}ä¸ª)']
        colors = ['#FF9999', '#66B3FF']
        
        plt.pie(sizes, labels=labels, autopct='%1.1f%%', 
                colors=colors, startangle=90, explode=(0.05, 0))
        
        plt.title('æ•°æ®é›†ç‰¹å¾ç±»å‹åˆ†å¸ƒ', fontsize=16, fontweight='bold', pad=20)
        
        # ä¿å­˜å›¾è¡¨
        chart_path = os.path.join(self.output_dir, 'figures', 'feature_type_distribution.png')
        plt.savefig(chart_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… ç‰¹å¾ç±»å‹åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {chart_path}")
    
    def create_target_distribution_chart(self, data):
        """åˆ›å»ºç›®æ ‡å˜é‡åˆ†å¸ƒå›¾è¡¨"""
        # æŸ¥æ‰¾ç›®æ ‡åˆ—
        target_col = None
        for col in ['deposit', 'Class', 'class']:
            if col in data.columns:
                target_col = col
                break
        
        if not target_col:
            print("âš ï¸  æœªæ‰¾åˆ°ç›®æ ‡å˜é‡ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
            return
        
        counts = data[target_col].value_counts()
        
        # åˆ›å»ºæ¡å½¢å›¾
        plt.figure(figsize=(10, 6))
        
        x_pos = np.arange(len(counts))
        colors = ['#4ECDC4', '#FF6B6B', '#95E1D3', '#F38181'][:len(counts)]
        
        bars = plt.bar(x_pos, counts.values, color=colors, alpha=0.8, edgecolor='black')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, value) in enumerate(zip(bars, counts.values)):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2, height + max(counts.values)*0.01,
                    f'{value:,}\n({value/sum(counts.values)*100:.1f}%)',
                    ha='center', va='bottom', fontsize=11)
        
        plt.xticks(x_pos, counts.index.astype(str), fontsize=12)
        plt.title(f'ç›®æ ‡å˜é‡ "{target_col}" åˆ†å¸ƒ', fontsize=16, fontweight='bold')
        plt.ylabel('æ ·æœ¬æ•°é‡', fontsize=14)
        plt.grid(axis='y', alpha=0.3, linestyle='--')
        
        # ä¿å­˜å›¾è¡¨
        chart_path = os.path.join(self.output_dir, 'figures', 'target_variable_distribution.png')
        plt.tight_layout()
        plt.savefig(chart_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… ç›®æ ‡å˜é‡åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {chart_path}")
    
    def generate_statistics_tables(self, data):
        """ç”Ÿæˆç»Ÿè®¡è¡¨æ ¼"""
        print("\n" + "-"*50)
        print("ğŸ“‹ ç”Ÿæˆç»Ÿè®¡è¡¨æ ¼")
        print("-"*50)
        
        # 1. æ•°å€¼ç‰¹å¾ç»Ÿè®¡è¡¨
        numeric_cols = data.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) > 0:
            numeric_stats = data[numeric_cols].describe().round(2)
            numeric_stats.loc['missing'] = data[numeric_cols].isnull().sum()
            numeric_stats.loc['missing_pct'] = (data[numeric_cols].isnull().sum() / len(data) * 100).round(2)
            
            # ä¿å­˜ä¸ºCSV
            numeric_path = os.path.join(self.output_dir, 'tables', 'numeric_features_statistics.csv')
            numeric_stats.to_csv(numeric_path)
            
            print(f"ğŸ“Š æ•°å€¼ç‰¹å¾ç»Ÿè®¡è¡¨:")
            print(f"  å…± {len(numeric_cols)} ä¸ªæ•°å€¼ç‰¹å¾")
            print(f"  å·²ä¿å­˜åˆ°: {numeric_path}")
        
        # 2. ç±»åˆ«ç‰¹å¾ç»Ÿè®¡è¡¨
        categorical_cols = data.select_dtypes(include=['object']).columns
        
        if len(categorical_cols) > 0:
            cat_stats = []
            for col in categorical_cols:
                unique_vals = data[col].unique()
                missing_count = data[col].isnull().sum()
                
                if len(data[col].mode()) > 0:
                    top_value = data[col].mode().iloc[0]
                    top_freq = (data[col] == top_value).sum()
                    top_pct = (top_freq / len(data) * 100).round(2)
                else:
                    top_value = 'N/A'
                    top_freq = 0
                    top_pct = 0
                
                cat_stats.append({
                    'feature': col,
                    'unique_values': len(unique_vals),
                    'missing': missing_count,
                    'missing_pct': (missing_count / len(data) * 100).round(2),
                    'most_common': str(top_value),
                    'most_common_count': top_freq,
                    'most_common_pct': top_pct
                })
            
            # ä¿å­˜ä¸ºCSV
            cat_stats_df = pd.DataFrame(cat_stats)
            cat_path = os.path.join(self.output_dir, 'tables', 'categorical_features_statistics.csv')
            cat_stats_df.to_csv(cat_path, index=False)
            
            print(f"ğŸ“Š ç±»åˆ«ç‰¹å¾ç»Ÿè®¡è¡¨:")
            print(f"  å…± {len(categorical_cols)} ä¸ªç±»åˆ«ç‰¹å¾")
            print(f"  å·²ä¿å­˜åˆ°: {cat_path}")
    
    def create_summary_report(self, stats, data):
        """åˆ›å»ºç®€è¦æ€»ç»“æŠ¥å‘Š"""
        print("\n" + "-"*50)
        print("ğŸ“ ç”Ÿæˆæ€»ç»“æŠ¥å‘Š")
        print("-"*50)
        
        report_content = f"""æ•°æ®é›†åŸºç¡€ç»Ÿè®¡åˆ†ææŠ¥å‘Š
========================================

ä¸€ã€æ•°æ®é›†åŸºæœ¬ä¿¡æ¯
------------------
- æ€»æ ·æœ¬æ•°: {stats['dataset_info']['samples']:,}
- æ€»ç‰¹å¾æ•°: {stats['dataset_info']['features']}
- æ•°å€¼å‹ç‰¹å¾: {stats['data_type_distribution']['numeric']['count']}ä¸ª
- ç±»åˆ«å‹ç‰¹å¾: {stats['data_type_distribution']['categorical']['count']}ä¸ª

äºŒã€ç›®æ ‡å˜é‡ä¿¡æ¯
---------------
"""
        
        if 'target_info' in stats and stats['target_info'].get('found', True):
            target_col = stats['target_info'].get('column_name', 'N/A')
            report_content += f"- ç›®æ ‡å˜é‡: {target_col}\n"
            
            for label, info in stats.get('target_distribution', {}).items():
                report_content += f"  - {label}: {info['count']:,} ä¸ª ({info['percentage']}%)\n"
            
            if stats['target_info'].get('imbalance_ratio'):
                report_content += f"- ç±»åˆ«ä¸å¹³è¡¡æ¯”ä¾‹: {stats['target_info']['imbalance_ratio']}:1\n"
        else:
            report_content += "- æœªæ£€æµ‹åˆ°ç›®æ ‡å˜é‡\n"
        
        report_content += f"""
ä¸‰ã€ç»“æœæ–‡ä»¶
-----------
æ‰€æœ‰åˆ†æç»“æœä¿å­˜åœ¨: {self.output_dir}

â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ feature_type_distribution.png    # ç‰¹å¾ç±»å‹åˆ†å¸ƒå›¾
â”‚   â””â”€â”€ target_variable_distribution.png  # ç›®æ ‡å˜é‡åˆ†å¸ƒå›¾
â””â”€â”€ tables/
    â”œâ”€â”€ basic_statistics.json            # åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
    â”œâ”€â”€ numeric_features_statistics.csv   # æ•°å€¼ç‰¹å¾ç»Ÿè®¡
    â””â”€â”€ categorical_features_statistics.csv # ç±»åˆ«ç‰¹å¾ç»Ÿè®¡

åˆ†ææ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = os.path.join(self.output_dir, 'analysis_summary.txt')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ… æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        
        # åœ¨æ§åˆ¶å°ä¹Ÿæ˜¾ç¤ºæŠ¥å‘Š
        print("\n" + report_content)
    
    def create_all_feature_distributions(self, data, max_categories=20):
        """åˆ›å»ºæ‰€æœ‰ç‰¹å¾çš„åˆ†å¸ƒæŸ±çŠ¶å›¾ï¼Œæ¯è¡Œ3ä¸ª"""
        print("\n" + "="*60)
        print("ğŸ“Š ç”Ÿæˆæ‰€æœ‰ç‰¹å¾åˆ†å¸ƒå›¾ (æ¯è¡Œ3ä¸ª)")
        print("="*60)
        
        # åˆ†ç¦»æ•°å€¼å‹å’Œç±»åˆ«å‹ç‰¹å¾
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = data.select_dtypes(include=['object']).columns.tolist()
        
        # æ’é™¤ç›®æ ‡å˜é‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        target_col = None
        for col in ['deposit', 'Class', 'class', 'target', 'y']:
            if col in data.columns:
                target_col = col
                break
        
        if target_col:
            if target_col in numeric_cols:
                numeric_cols.remove(target_col)
            if target_col in categorical_cols:
                categorical_cols.remove(target_col)
        
        all_features = categorical_cols + numeric_cols
        
        if not all_features:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å¯ç»˜åˆ¶çš„ç‰¹å¾")
            return
        
        print(f"ğŸ“ˆ å…± {len(all_features)} ä¸ªç‰¹å¾éœ€è¦ç»˜å›¾")
        print(f"  - ç±»åˆ«å‹: {len(categorical_cols)} ä¸ª")
        print(f"  - æ•°å€¼å‹: {len(numeric_cols)} ä¸ª")
        
        # è®¡ç®—éœ€è¦çš„è¡Œæ•°ï¼ˆæ¯è¡Œ3ä¸ªï¼‰
        n_features = len(all_features)
        n_rows = (n_features + 2) // 3  # å‘ä¸Šå–æ•´
        
        # è®¾ç½®ç”»å¸ƒå¤§å°
        fig_width = 15
        fig_height = 5 * n_rows
        
        # åˆ›å»ºå¤§å›¾
        fig, axes = plt.subplots(n_rows, 3, figsize=(fig_width, fig_height))
        fig.suptitle('æ‰€æœ‰ç‰¹å¾åˆ†å¸ƒå›¾', fontsize=18, fontweight='bold', y=0.995)
        
        # å¦‚æœåªæœ‰ä¸€è¡Œï¼Œaxesä¸æ˜¯äºŒç»´æ•°ç»„ï¼Œéœ€è¦è½¬æ¢
        if n_rows == 1:
            axes = axes.reshape(1, -1) if hasattr(axes, 'reshape') else np.array([axes])
        
        # æ‰å¹³åŒ–axesä¾¿äºè¿­ä»£
        axes_flat = axes.flatten()
        
        # éå†æ‰€æœ‰ç‰¹å¾å¹¶ç»˜åˆ¶
        for idx, feature in enumerate(all_features):
            ax = axes_flat[idx]
            
            # å¤„ç†ç±»åˆ«å‹ç‰¹å¾
            if feature in categorical_cols:
                value_counts = data[feature].value_counts().head(max_categories)
                
                # å¦‚æœç±»åˆ«å¤ªå¤šï¼Œåˆ†ç»„æ˜¾ç¤º
                if len(data[feature].unique()) > max_categories:
                    value_counts = data[feature].value_counts().head(max_categories)
                    title_suffix = f" (Top {max_categories})"
                else:
                    title_suffix = ""
                
                bars = ax.bar(range(len(value_counts)), value_counts.values, 
                            color=plt.cm.Set3(idx % 12), alpha=0.8, edgecolor='black')
                
                ax.set_xticks(range(len(value_counts)))
                ax.set_xticklabels(value_counts.index.astype(str), rotation=45, ha='right', fontsize=8)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for i, bar in enumerate(bars):
                    height = bar.get_height()
                    ax.text(bar.get_x() + bar.get_width()/2, height,
                        f'{int(height)}', ha='center', va='bottom', fontsize=8)
                
                ax.set_title(f'{feature}{title_suffix}', fontsize=11, fontweight='bold')
                ax.set_ylabel('é¢‘æ•°', fontsize=9)
                ax.tick_params(axis='both', labelsize=8)
                
            # å¤„ç†æ•°å€¼å‹ç‰¹å¾
            else:
                # ä½¿ç”¨ç›´æ–¹å›¾
                data_values = data[feature].dropna()
                
                # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å”¯ä¸€å€¼
                unique_vals = data_values.nunique()
                if unique_vals > 50:
                    # ä½¿ç”¨ç›´æ–¹å›¾
                    ax.hist(data_values, bins=30, color=plt.cm.Set3(idx % 12), 
                        alpha=0.8, edgecolor='black')
                    ax.set_title(f'{feature} (ç›´æ–¹å›¾)', fontsize=11, fontweight='bold')
                else:
                    # ä½¿ç”¨æ¡å½¢å›¾æ˜¾ç¤ºåˆ†å¸ƒ
                    value_counts = data_values.value_counts().head(20)
                    bars = ax.bar(range(len(value_counts)), value_counts.values,
                                color=plt.cm.Set3(idx % 12), alpha=0.8, edgecolor='black')
                    ax.set_xticks(range(len(value_counts)))
                    ax.set_xticklabels(value_counts.index.astype(str), rotation=45, ha='right', fontsize=8)
                    ax.set_title(f'{feature} (ç¦»æ•£å€¼)', fontsize=11, fontweight='bold')
                
                ax.set_ylabel('é¢‘æ•°', fontsize=9)
                ax.tick_params(axis='both', labelsize=8)
            
            # æ·»åŠ ç½‘æ ¼
            ax.grid(True, alpha=0.3, axis='y', linestyle='--')
        
        # éšè—å¤šä½™çš„å­å›¾
        for idx in range(len(all_features), len(axes_flat)):
            axes_flat[idx].set_visible(False)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        chart_path = os.path.join(self.output_dir, 'figures', 'all_features_distribution.png')
        plt.savefig(chart_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… æ‰€æœ‰ç‰¹å¾åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {chart_path}")
        print(f"   é¢„è§ˆ: {n_rows} è¡Œ Ã— 3 åˆ— = {n_rows * 3} ä¸ªå­å›¾ä½ç½®ï¼Œå®é™…ä½¿ç”¨ {len(all_features)} ä¸ª")

    
    def run_full_analysis(self):
        """è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
        print("="*60)
        print("ğŸš€ å¼€å§‹æ•°æ®é›†åŸºç¡€ç»Ÿè®¡åˆ†æ")
        print("="*60)
        
        # 1. åŠ è½½æ•°æ®
        data = self.load_data()
        if data is None:
            return None
        
        # 2. æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯
        print("\nğŸ“„ æ•°æ®é¢„è§ˆ (å‰5è¡Œ):")
        print(data.head())
        print(f"\nğŸ“‹ æ‰€æœ‰ç‰¹å¾: {', '.join(data.columns.tolist())}")
        
        # 3. è·å–åŸºç¡€ç»Ÿè®¡
        stats = self.get_basic_stats(data)
        
        # 4. åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
        print("\n" + "="*60)
        print("ğŸ¨ åˆ›å»ºå¯è§†åŒ–å›¾è¡¨")
        print("="*60)
        self.create_feature_type_chart(data)
        self.create_target_distribution_chart(data)
        
        # ğŸ†• æ–°å¢ï¼šåˆ›å»ºæ‰€æœ‰ç‰¹å¾åˆ†å¸ƒå›¾
        self.create_all_feature_distributions(data)
        
        # 5. ç”Ÿæˆç»Ÿè®¡è¡¨æ ¼
        self.generate_statistics_tables(data)
        
        # 6. åˆ›å»ºæ€»ç»“æŠ¥å‘Š
        self.create_summary_report(stats, data)
        
        print("\n" + "="*60)
        print("âœ… åˆ†æå®Œæˆï¼")
        print("="*60)
        print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {self.output_dir}")
        
        return stats

def run_analysis():
    """è¿è¡Œåˆ†æçš„å‡½æ•°"""
    analyzer = BasicDataAnalysis()
    return analyzer.run_full_analysis()

def main():
    """ä¸»å‡½æ•°"""
    results = run_analysis()
    
    if results:
        print("\nğŸ‰ åŸºç¡€ç»Ÿè®¡åˆ†ææˆåŠŸå®Œæˆï¼")
        print(f"è¯·æŸ¥çœ‹æ–‡ä»¶å¤¹: ./preprocess_dataset/basic_data_analysis")
    else:
        print("\nâŒ åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")

if __name__ == "__main__":
    # è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡æ˜¾ç¤º
    try:
        import matplotlib
        matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
        matplotlib.rcParams['axes.unicode_minus'] = False
    except:
        pass
    main()
