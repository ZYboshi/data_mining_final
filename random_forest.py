# random_forest_model.py
"""
éšæœºæ£®æ—æ¨¡å‹å»ºæ¨¡
ä½¿ç”¨åæŠ˜äº¤å‰éªŒè¯
"""
import pandas as pd
import numpy as np
import os
import time
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (classification_report, confusion_matrix, 
                           roc_auc_score, accuracy_score, precision_score, 
                           recall_score, f1_score, roc_curve)
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®matplotlib
try:
    import matplotlib
    matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
    matplotlib.rcParams['axes.unicode_minus'] = False
except:
    pass

def create_directories():
    """åˆ›å»ºå¿…è¦çš„æ–‡ä»¶å¤¹"""
    directories = [
        './result/random_forest',
        './model_checkpoint/random_forest'
    ]
    
    for directory in directories:
        if not os.path.exists(directory):
            os.makedirs(directory)
            print(f"âœ… åˆ›å»ºç›®å½•: {directory}")

def load_and_split_data():
    """åŠ è½½æ•°æ®"""
    print("ğŸ“‚ åŠ è½½æ•°æ®...")
    data = pd.read_csv('./dataset/data_label_encoded.csv')
    
    X = data.drop('deposit', axis=1)
    y = data['deposit']
    
    print(f"æ•°æ®é›†å½¢çŠ¶: {data.shape}")
    print(f"ç±»åˆ«åˆ†å¸ƒ:\n{y.value_counts()}")
    print(f"æ­£ç±»æ¯”ä¾‹: {y.mean():.2%}")
    
    return X, y

def train_random_forest_base(X, y):
    """è®­ç»ƒåŸºç¡€çš„éšæœºæ£®æ—æ¨¡å‹"""
    print("\nğŸ² è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹...")
    
    # éšæœºæ£®æ—å‚æ•°è®¾ç½®
    rf_model = RandomForestClassifier(
        n_estimators=100,      # æ ‘çš„æ•°é‡
        max_depth=None,        # æ ‘çš„æœ€å¤§æ·±åº¦
        min_samples_split=2,   # å†…éƒ¨èŠ‚ç‚¹åˆ†è£‚æ‰€éœ€æœ€å°æ ·æœ¬æ•°
        min_samples_leaf=1,    # å¶èŠ‚ç‚¹æ‰€éœ€æœ€å°æ ·æœ¬æ•°
        max_features='sqrt',   # æ¯æ£µæ ‘è€ƒè™‘çš„æœ€å¤§ç‰¹å¾æ•°
        random_state=42,
        n_jobs=-1,             # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
        class_weight='balanced_subsample'  # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
    )
    
    return rf_model

def cross_validation_analysis(model, X, y):
    """åæŠ˜äº¤å‰éªŒè¯åˆ†æ"""
    print("\nğŸ“Š åæŠ˜äº¤å‰éªŒè¯åˆ†æ...")
    
    # åˆ›å»ºåˆ†å±‚10æŠ˜äº¤å‰éªŒè¯
    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
    
    cv_metrics = {
        'fold': [],
        'accuracy': [],
        'precision': [],
        'recall': [],
        'f1': [],
        'auc': [],
        'train_time': []
    }
    
    y_all_true = []
    y_all_pred = []
    y_all_proba = []
    
    fold_num = 1
    total_start_time = time.time()
    
    for train_idx, val_idx in cv.split(X, y):
        fold_start_time = time.time()
        
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
        
        # è®­ç»ƒ
        model.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_pred = model.predict(X_val)
        y_proba = model.predict_proba(X_val)[:, 1]
        
        # è®°å½•æ—¶é—´
        train_time = time.time() - fold_start_time
        
        # è®¡ç®—æŒ‡æ ‡
        cv_metrics['fold'].append(fold_num)
        cv_metrics['accuracy'].append(accuracy_score(y_val, y_pred))
        cv_metrics['precision'].append(precision_score(y_val, y_pred, zero_division=0))
        cv_metrics['recall'].append(recall_score(y_val, y_pred, zero_division=0))
        cv_metrics['f1'].append(f1_score(y_val, y_pred, zero_division=0))
        cv_metrics['auc'].append(roc_auc_score(y_val, y_proba))
        cv_metrics['train_time'].append(train_time)
        
        # æ”¶é›†æ‰€æœ‰é¢„æµ‹
        y_all_true.extend(y_val)
        y_all_pred.extend(y_pred)
        y_all_proba.extend(y_proba)
        
        print(f"  ç¬¬{fold_num}æŠ˜: å‡†ç¡®ç‡={accuracy_score(y_val, y_pred):.4f}, "
              f"è®­ç»ƒæ—¶é—´={train_time:.2f}ç§’")
        
        fold_num += 1
    
    total_time = time.time() - total_start_time
    
    # åˆ›å»ºæŒ‡æ ‡DataFrame
    metrics_df = pd.DataFrame(cv_metrics)
    
    print("\n" + "="*50)
    print("ğŸ“ˆ äº¤å‰éªŒè¯ç»“æœæ±‡æ€»:")
    print("="*50)
    
    print("\nå„æŠ˜è¯¦ç»†æŒ‡æ ‡:")
    print(metrics_df[['fold', 'accuracy', 'precision', 'recall', 'f1', 'auc']].round(4))
    
    print(f"\nğŸ† å¹³å‡æŒ‡æ ‡ (Â±æ ‡å‡†å·®):")
    for metric in ['accuracy', 'precision', 'recall', 'f1', 'auc']:
        mean_val = metrics_df[metric].mean()
        std_val = metrics_df[metric].std()
        print(f"  {metric}: {mean_val:.4f} Â± {std_val:.4f}")
    
    print(f"\nâ±ï¸  æ—¶é—´ç»Ÿè®¡:")
    print(f"  å¹³å‡æ¯æŠ˜è®­ç»ƒæ—¶é—´: {metrics_df['train_time'].mean():.2f}ç§’")
    print(f"  æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f}ç§’")
    
    return metrics_df, np.array(y_all_true), np.array(y_all_pred), np.array(y_all_proba), cv

def analyze_feature_importance(model, X, top_n=15):
    """åˆ†æç‰¹å¾é‡è¦æ€§"""
    print("\nğŸ”¬ ç‰¹å¾é‡è¦æ€§åˆ†æ...")
    
    # è·å–ç‰¹å¾é‡è¦æ€§
    feature_importance = model.feature_importances_
    
    # åˆ›å»ºDataFrame
    importance_df = pd.DataFrame({
        'feature': X.columns,
        'importance': feature_importance
    })
    
    # æ’åº
    importance_df = importance_df.sort_values('importance', ascending=False)
    
    print(f"\nTop {top_n} æœ€é‡è¦çš„ç‰¹å¾:")
    print(importance_df.head(top_n).round(4))
    
    # å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§
    plt.figure(figsize=(12, 8))
    
    top_features = importance_df.head(top_n)
    colors = plt.cm.viridis(np.linspace(0.3, 1, len(top_features)))
    
    plt.barh(range(len(top_features)), top_features['importance'], color=colors)
    plt.yticks(range(len(top_features)), top_features['feature'])
    plt.xlabel('Feature Importance Score')
    plt.title(f'Random Forest - Top {top_n} Feature Importance')
    plt.gca().invert_yaxis()  # æœ€é‡è¦çš„åœ¨é¡¶éƒ¨
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_path = './result/random_forest/feature_importance.png'
    plt.savefig(save_path, dpi=100, bbox_inches='tight')
    print(f"âœ… ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜åˆ°: {save_path}")
    plt.show()
    
    return importance_df

def train_final_model(X, y):
    """è®­ç»ƒæœ€ç»ˆçš„éšæœºæ£®æ—æ¨¡å‹"""
    print("\nğŸ¯ è®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
    
    # åˆ†å‰²æ•°æ®é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # æœ€ç»ˆæ¨¡å‹ - å¯ä»¥è°ƒæ•´å‚æ•°
    final_model = RandomForestClassifier(
        n_estimators=150,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        max_features='sqrt',
        random_state=42,
        n_jobs=-1,
        class_weight='balanced_subsample'
    )
    
    # è®­ç»ƒ
    start_time = time.time()
    final_model.fit(X_train, y_train)
    train_time = time.time() - start_time
    
    print(f"æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {train_time:.2f}ç§’")
    
    # é¢„æµ‹
    y_pred = final_model.predict(X_test)
    y_proba = final_model.predict_proba(X_test)[:, 1]
    
    # è¯„ä¼°
    print("\nğŸ“‹ æµ‹è¯•é›†è¯„ä¼°ç»“æœ:")
    print(classification_report(y_test, y_pred))
    
    print(f"AUC Score: {roc_auc_score(y_test, y_proba):.4f}")
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_test, y_pred)
    print(f"\næ··æ·†çŸ©é˜µ:\n{cm}")
    
    # å¯è§†åŒ–æ··æ·†çŸ©é˜µ
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['No Deposit', 'Deposit'],
                yticklabels=['No Deposit', 'Deposit'])
    plt.title('Random Forest - Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    
    save_path = './result/random_forest/confusion_matrix.png'
    plt.savefig(save_path, dpi=100, bbox_inches='tight')
    print(f"âœ… æ··æ·†çŸ©é˜µå›¾å·²ä¿å­˜åˆ°: {save_path}")
    plt.show()
    
    # ROCæ›²çº¿
    fpr, tpr, thresholds = roc_curve(y_test, y_proba)
    
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, 'b-', label=f'Random Forest (AUC = {roc_auc_score(y_test, y_proba):.3f})')
    plt.plot([0, 1], [0, 1], 'r--', label='Random Classifier')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve - Random Forest')
    plt.legend(loc='lower right')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    save_path = './result/random_forest/roc_curve.png'
    plt.savefig(save_path, dpi=100, bbox_inches='tight')
    print(f"âœ… ROCæ›²çº¿å›¾å·²ä¿å­˜åˆ°: {save_path}")
    plt.show()
    
    return final_model, X_test, y_test, y_pred, y_proba

def hyperparameter_tuning(X, y):
    """éšæœºæ£®æ—è¶…å‚æ•°è°ƒä¼˜"""
    print("\nâš™ï¸  è¶…å‚æ•°è°ƒä¼˜ï¼ˆç½‘æ ¼æœç´¢ï¼‰...")
    
    from sklearn.model_selection import GridSearchCV
    
    # ç®€åŒ–ç‰ˆçš„ç½‘æ ¼æœç´¢ï¼ˆé¿å…è€—æ—¶è¿‡é•¿ï¼‰
    param_grid = {
        'n_estimators': [50, 100, 150],
        'max_depth': [5, 10, 15, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    }
    
    rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)
    
    # ä½¿ç”¨è¾ƒå°çš„ç½‘æ ¼æœç´¢
    grid_search = GridSearchCV(
        rf_base, 
        param_grid, 
        cv=3,  # ç”¨3æŠ˜å‡å°‘æ—¶é—´
        scoring='roc_auc',
        n_jobs=-1,
        verbose=1
    )
    
    print("æ­£åœ¨è¿›è¡Œç½‘æ ¼æœç´¢ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
    grid_search.fit(X, y)
    
    print(f"\nâœ¨ æœ€ä½³å‚æ•°: {grid_search.best_params_}")
    print(f"âœ¨ æœ€ä½³äº¤å‰éªŒè¯AUC: {grid_search.best_score_:.4f}")
    
    return grid_search.best_estimator_, grid_search.best_params_

def save_results(model, metrics_df, importance_df):
    """ä¿å­˜æ¨¡å‹å’Œç»“æœ"""
    print("\nğŸ’¾ ä¿å­˜ç»“æœ...")
    
    import pickle
    
    # ä¿å­˜æ¨¡å‹
    model_path = './model_checkpoint/random_forest/random_forest_model.pkl'
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    
    # ä¿å­˜æŒ‡æ ‡
    metrics_path = './result/random_forest/cross_validation_metrics.csv'
    metrics_df.to_csv(metrics_path, index=False)
    print(f"âœ… äº¤å‰éªŒè¯æŒ‡æ ‡å·²ä¿å­˜åˆ°: {metrics_path}")
    
    # ä¿å­˜ç‰¹å¾é‡è¦æ€§
    importance_path = './result/random_forest/feature_importance.csv'
    importance_df.to_csv(importance_path, index=False)
    print(f"âœ… ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜åˆ°: {importance_path}")
    
    # ä¿å­˜å‚æ•°
    params_path = './result/random_forest/model_params.txt'
    with open(params_path, 'w') as f:
        f.write(f"Model Parameters:\n")
        for key, value in model.get_params().items():
            f.write(f"{key}: {value}\n")
    print(f"âœ… æ¨¡å‹å‚æ•°å·²ä¿å­˜åˆ°: {params_path}")

def compare_with_logistic(logistic_model=None):
    """ä¸é€»è¾‘å›å½’æ¨¡å‹æ¯”è¾ƒ"""
    print("\nâš–ï¸  æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ...")
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ é€»è¾‘å›å½’å¯¹æ¯”
    # å¦‚æœæä¾›äº†é€»è¾‘å›å½’æ¨¡å‹ï¼Œå¯ä»¥è¿›è¡Œæ¯”è¾ƒ
    if logistic_model:
        print("éœ€è¦åŠ è½½é€»è¾‘å›å½’æ¨¡å‹è¿›è¡Œæ¯”è¾ƒ...")
        # å¯¹æ¯”ä»£ç å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ 

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸŒ² Random Forest Modeling (10-Fold CV)")
    print("=" * 60)
    
    # 0. åˆ›å»ºç›®å½•
    create_directories()
    
    # 1. åŠ è½½æ•°æ®
    X, y = load_and_split_data()
    
    # 2. è®­ç»ƒåŸºç¡€æ¨¡å‹å¹¶è¿›è¡Œäº¤å‰éªŒè¯
    rf_model = train_random_forest_base(X, y)
    metrics_df, y_all_true, y_all_pred, y_all_proba, cv = cross_validation_analysis(rf_model, X, y)
    
    # 3. åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒä»¥è·å–ç‰¹å¾é‡è¦æ€§
    print("\n" + "="*40)
    print("Training model on full dataset...")
    rf_model_full = RandomForestClassifier(
        n_estimators=100,
        random_state=42,
        n_jobs=-1
    )
    rf_model_full.fit(X, y)
    
    # 4. ç‰¹å¾é‡è¦æ€§åˆ†æ
    importance_df = analyze_feature_importance(rf_model_full, X, top_n=15)
    
    # 5. è®­ç»ƒæœ€ç»ˆæ¨¡å‹
    final_model, X_test, y_test, y_pred, y_proba = train_final_model(X, y)
    
    # 6. ï¼ˆå¯é€‰ï¼‰è¶…å‚æ•°è°ƒä¼˜
    want_tuning = input("\næ˜¯å¦è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜ï¼Ÿ(y/n, å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ): ").lower()
    if want_tuning == 'y':
        try:
            best_model, best_params = hyperparameter_tuning(X, y)
            final_model = best_model
            print(f"ä½¿ç”¨è°ƒä¼˜åçš„æ¨¡å‹è¿›è¡Œæœ€ç»ˆè¯„ä¼°...")
        except Exception as e:
            print(f"è°ƒä¼˜è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            print("ç»§ç»­ä½¿ç”¨åŸºç¡€æ¨¡å‹...")
    
    # 7. ä¿å­˜æ‰€æœ‰ç»“æœ
    save_results(final_model, metrics_df, importance_df)
    
    print("\n" + "="*60)
    print("âœ… Random Forest Modeling Completed Successfully!")
    print("="*60)
    print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - ./result/random_forest/")
    print(f"     â€¢ feature_importance.png (ç‰¹å¾é‡è¦æ€§å›¾)")
    print(f"     â€¢ confusion_matrix.png (æ··æ·†çŸ©é˜µ)")
    print(f"     â€¢ roc_curve.png (ROCæ›²çº¿)")
    print(f"     â€¢ cross_validation_metrics.csv (äº¤å‰éªŒè¯æŒ‡æ ‡)")
    print(f"     â€¢ feature_importance.csv (ç‰¹å¾é‡è¦æ€§æ•°æ®)")
    print(f"  - ./model_checkpoint/random_forest/")
    print(f"     â€¢ random_forest_model.pkl (è®­ç»ƒå¥½çš„æ¨¡å‹)")
    print(f"\nğŸ“Š æ€§èƒ½æ€»ç»“:")
    print(f"  å¹³å‡å‡†ç¡®ç‡: {metrics_df['accuracy'].mean():.4f}")
    print(f"  å¹³å‡AUC: {metrics_df['auc'].mean():.4f}")
    print(f"  å¹³å‡F1åˆ†æ•°: {metrics_df['f1'].mean():.4f}")
    
    return final_model, metrics_df, importance_df

if __name__ == "__main__":
    try:
        start_time = time.time()
        model, metrics_df, importance_df = main()
        total_time = time.time() - start_time
        
        print(f"\nâ±ï¸  æ€»è¿è¡Œæ—¶é—´: {total_time:.2f}ç§’")
        print("ğŸ‰ éšæœºæ£®æ—å»ºæ¨¡å®Œæˆ!")
        
    except FileNotFoundError as e:
        print(f"\nâŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        print("è¯·ç¡®ä¿ './dataset/data_label_encoded.csv' æ–‡ä»¶å­˜åœ¨")
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
